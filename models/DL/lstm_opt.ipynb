{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y_vector(df, lags, future):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - lags - future):\n",
    "        x_window_rows = df.iloc[i:i + lags]\n",
    "        x_row = [list(x_window_rows.iloc[j]) for j in range(lags)]\n",
    "        X.append(x_row)\n",
    "        y_window_rows = df.iloc[i + lags:i + lags + future]\n",
    "        y_row = [y_window_rows.iloc[j]['Detections'] for j in range(future)]\n",
    "        y.append(y_row)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def df_to_X_y_standard(df, lags):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - lags):\n",
    "        window_rows = df.iloc[i:i + lags]\n",
    "        row = [list(window_rows.iloc[j]) for j in range(lags)]\n",
    "        X.append(row)\n",
    "        label = df.iloc[i + lags]\n",
    "        y.append(label['Detections'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def get_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop(['WeatherDescription', 'Unnamed: 0', 'index'], axis=1)\n",
    "    df = pd.get_dummies(df, columns=['WeatherMain'], prefix='WeatherMain')\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df['Year'] = df['Timestamp'].dt.year\n",
    "    df['Month'] = df['Timestamp'].dt.month\n",
    "    df['Day'] = df['Timestamp'].dt.day\n",
    "    df['Hour'] = df['Timestamp'].dt.hour\n",
    "    df = df.drop(['Timestamp', 'WeatherMain_Snow', 'Year'], axis=1)\n",
    "    return df_to_X_y_vector(df, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../train_belgrade.csv'\n",
    "X, y = get_df(path)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "X_train_raw, X_temp, y_train_raw, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val_raw, X_test_raw, y_val_raw, y_test_raw = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train_raw, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_raw, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val_raw, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val_raw, dtype=torch.float32)\n",
    "\n",
    "# permute since we have batch_first=True\n",
    "X_train = X_train.permute(0, 1, 2)\n",
    "X_val = X_val.permute(0, 1, 2)\n",
    "\n",
    "# y_train = y_train.view(-1, y_train.shape[0], y_train.shape[1])\n",
    "# y_val = y_val.view(-1, y_val.shape[0], y_val.shape[1]) \n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, **kwargs):\n",
    "        super().__init__()\n",
    "        self.last_layer = kwargs.pop('last_layer', False)\n",
    "        self.lstm = nn.GRU(input_dim, hidden_size, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        if self.last_layer:\n",
    "            return output[:, -1, :]\n",
    "        return output\n",
    "\n",
    "\n",
    "def create_model(trial, input_size, output_size):\n",
    "    # Hyperparameters to be tuned\n",
    "    hidden_size = trial.suggest_int('hidden_size', 50, 200)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    \n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "        input_dim = input_size if i == 0 else hidden_size\n",
    "        layers.append(CustomLSTM(input_dim, hidden_size, batch_first=True, dropout=dropout if i+1 < num_layers else 0, last_layer=i+1 == num_layers))\n",
    "    layers.append(nn.Linear(hidden_size, output_size))\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Assuming data preparation steps are already done, and you have X_train, y_train, X_val, y_val as tensors\n",
    "    # print('Inputs:', X_train.shape, y_train.shape)\n",
    "    \n",
    "    model = create_model(trial, input_size=8, output_size=5)\n",
    "\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=trial.suggest_float('lr', 1e-5, 1e-2, log=True))\n",
    "    \n",
    "    # Example: Train the model\n",
    "    epochs = 10\n",
    "    mini_batch_size = 32\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(X_train), mini_batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_train[i:i+mini_batch_size])\n",
    "            # print('Outputs', output.shape, y_train[i:i+mini_batch_size].shape)\n",
    "            loss = criterion(output, y_train[i:i+mini_batch_size])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output = model(X_val)\n",
    "            val_loss = criterion(val_output, y_val)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {val_loss.item()}')\n",
    "    # save model\n",
    "    output_path = pathlib.Path('./lstm_models')\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    torch.save(model.state_dict(), output_path/f'model_{trial.number}.pth')\n",
    "\n",
    "            \n",
    "    return val_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f'Best trial score: {best_trial.value}')\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "X_test = torch.tensor(X_test_raw, dtype=torch.float32)\n",
    "X_test = X_test.permute(0, 1, 2)\n",
    "y_test = torch.tensor(y_test_raw, dtype=torch.float32)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = create_model(best_trial, input_size=8, output_size=5)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(f'./lstm_models/model_{best_trial.number}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    test_output = model(X_test)\n",
    "    print(test_output, y_test)\n",
    "    test_loss = criterion(test_output, y_test)\n",
    "    \n",
    "print(f'Test loss: {test_loss.item()}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
